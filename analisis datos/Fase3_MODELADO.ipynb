{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2af2ba6",
   "metadata": {},
   "source": [
    "# ✅ 03 - MODELADO (03_modelado.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53ec3a",
   "metadata": {},
   "source": [
    "✔️ Objetivo:\n",
    "Aplicar modelos predictivos o de segmentación según el problema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ec18c6",
   "metadata": {},
   "source": [
    "| Tarea                               | Código de Ejemplo                                             | Consejo Profesional                                  |\n",
    "| ----------------------------------- | ------------------------------------------------------------- | ---------------------------------------------------- |\n",
    "| Cargar datos                        | `df = pd.read_csv('data/processed/datos_limpios.csv')`        | Asegura que no hay data leakage.                     |\n",
    "| Definir variables                   | `X = df.drop('target', axis=1)`<br>`y = df['target']`         | `X` son predictores, `y` es lo que quieres predecir. |\n",
    "| Dividir en train/test               | `train_test_split(X, y, test_size=0.2, random_state=42)`      | `random_state` da reproducibilidad.                  |\n",
    "| Escalado (otra vez si es necesario) | `scaler.fit_transform(X_train)`<br>`scaler.transform(X_test)` | Nunca hagas `.fit()` sobre el conjunto de prueba.    |\n",
    "| Entrenar modelo base                | `LogisticRegression().fit(X_train, y_train)`                  | Comienza simple antes de complicarte.                |\n",
    "| Validación cruzada                  | `cross_val_score(model, X_train, y_train, cv=5)`              | Ayuda a medir estabilidad del modelo.                |\n",
    "| Tuning de hiperparámetros           | `GridSearchCV` o `RandomizedSearchCV`                         | Mejora performance sin sobreajuste.                  |\n",
    "| Guardar modelo entrenado            | `joblib.dump(model, 'models/model.pkl')`                      | Guarda también el escalador si lo usaste.            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3332af",
   "metadata": {},
   "source": [
    "## 1. Importar datos procesados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6668186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/dataset_limpio.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78381e6",
   "metadata": {},
   "source": [
    "## [___] 2. Separar features y target\n",
    "\n",
    "- [___] Identifiqué correctamente la variable objetivo (target)\n",
    "\n",
    "- [___] Usé `.drop()` para separar las features (X)\n",
    "\n",
    "- [___] Verifiqué que `X` y `y` tengan el mismo número de filas\n",
    "\n",
    "- [___] Eliminé columnas innecesarias de `X` (como IDs o constantes)\n",
    "\n",
    "- [___] Guardé `X` y `y` en variables separadas\n",
    "\n",
    "\n",
    "\n",
    "Esta separación es la base sobre la cual se entrena y evalúa cualquier modelo supervisado.\n",
    "\n",
    "* Features (Características o Variables Predictoras): Son las variables de entrada que el modelo de machine learning utilizará para hacer predicciones.\n",
    "\n",
    "Target (Objetivo o Variable de Respuesta): Es la variable que intentamos predecir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de dataset\n",
    "df = pd.DataFrame({\n",
    "    'edad': [25, 32, 47],\n",
    "    'ingresos': [50000, 64000, 120000],\n",
    "    'compra': [0, 1, 1]  # Esta es la variable target\n",
    "})\n",
    "# Separar features (X) y target (y)\n",
    "X = df.drop('compra', axis=1)  # Eliminas la columna target para quedarte con las features\n",
    "y = df['compra']               # Solo la columna target\n",
    "\n",
    "# X\n",
    "#    edad  ingresos\n",
    "# 0    25     50000\n",
    "# 1    32     64000\n",
    "# 2    47    120000\n",
    "# \n",
    "# y\n",
    "# 0    0\n",
    "# 1    1\n",
    "# 2    1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e2c70",
   "metadata": {},
   "source": [
    "## [___] 3. Dividir en entrenamiento y test\n",
    "\n",
    " ¿Qué significa?\n",
    "\n",
    "En machine learning, dividir los datos en conjunto de entrenamiento y de prueba significa separar el dataset para:\n",
    "\n",
    "    Entrenar el modelo (conjunto de entrenamiento - training set): Es con lo que el modelo “aprende”.\n",
    "\n",
    "    Evaluar el modelo (conjunto de prueba - test set): Se usa para medir el rendimiento del modelo con datos nunca vistos por él.\n",
    "\n",
    "Esto evita el sobreajuste (overfitting), donde un modelo se aprende de memoria los datos y no generaliza bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34568eb3",
   "metadata": {},
   "source": [
    "## [✅] 3. Dividir en entrenamiento y test\n",
    "- [__] Importé `train_test_split` de `sklearn.model_selection`\n",
    "\n",
    "- [__] Apliqué la función usando `X` e `y`\n",
    "\n",
    "- [__] Usé un `test_size` adecuado (ej. 0.2 o 0.3)\n",
    "\n",
    "- [__] Usé `random_state` para reproducibilidad\n",
    "\n",
    "- [__] Verifiqué que las dimensiones coincidan con la división esperada\n",
    "\n",
    "- [__] (Opcional) Usé `stratify=y` si era clasificación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que ya tienes X (features) e y (target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23dbfd",
   "metadata": {},
   "source": [
    "| Parámetro      | Descripción                                                                                          |\n",
    "| -------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| `test_size`    | Proporción del conjunto de datos reservado para test. Ej: `0.2` → 20% test, 80% train                |\n",
    "| `random_state` | Fija una “semilla” para que la división sea reproducible (útil para pruebas)                         |\n",
    "| `shuffle`      | Por defecto `True`, baraja los datos antes de dividir. Puede ser `False` en series temporales        |\n",
    "| `stratify=y`   | (Opcional pero recomendado en clasificación) mantiene proporciones de clases iguales en train y test |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919c6e2",
   "metadata": {},
   "source": [
    "## [___] 4. Entrenar modelos base\n",
    "\n",
    "## [✅] 4. Entrenar modelos base\n",
    "- [__] Seleccioné modelos simples como LogisticRegression o DecisionTree\n",
    "\n",
    "- [__] Entrené cada modelo con `.fit(X_train, y_train)`\n",
    "\n",
    "- [__] Hice predicciones con `.predict(X_test)`\n",
    "\n",
    "- [__] Evalué con métricas básicas (accuracy, MAE, RMSE, etc.)\n",
    "\n",
    "- [__] Usé un modelo dummy como referencia mínima\n",
    "\n",
    "- [__] Guardé los resultados y los comparé entre sí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e2725",
   "metadata": {},
   "source": [
    "| Tarea             | Modelos sugeridos para empezar                                                         |\n",
    "| ----------------- | -------------------------------------------------------------------------------------- |\n",
    "| Clasificación     | `LogisticRegression`, `DecisionTreeClassifier`, `RandomForest`, `DummyClassifier`      |\n",
    "| Regresión         | `LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`, `DummyRegressor` |\n",
    "| Clustering        | `KMeans`, `DBSCAN`, `HierarchicalClustering`                                           |\n",
    "| Series temporales | `ARIMA`, `Prophet`, `LSTM`                                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e102f18",
   "metadata": {},
   "source": [
    "| Modelo                                             | Tipo de tarea                                   | ¿Para qué se usa?                                                      | Características clave                                      |\n",
    "| -------------------------------------------------- | ----------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------- |\n",
    "| **Linear Regression**                              | Regresión                                       | Predecir valores numéricos continuos (precio, temperatura, etc.)       | Modelo simple, fácil de interpretar                        |\n",
    "| **Logistic Regression**                            | Clasificación binaria                           | Clasificación entre dos clases (sí/no, 0/1, aprobado/no aprobado)      | Rápido, base para clasificación                            |\n",
    "| **Decision Tree**                                  | Regresión/Clasificación                         | Tareas con decisiones basadas en condiciones (reglas tipo árbol)       | Fácil de visualizar, puede sobreajustar                    |\n",
    "| **Random Forest**                                  | Regresión/Clasificación                         | Tareas generales, clasificación multiclase, regresión                  | Robusto, combina muchos árboles, reduce overfitting        |\n",
    "| **Gradient Boosting (XGBoost, LightGBM, etc.)**    | Regresión/Clasificación                         | Problemas complejos con alto rendimiento                               | Muy potente, tuning delicado, puede tardar más en entrenar |\n",
    "| **Support Vector Machines (SVM)**                  | Clasificación/Regresión                         | Clasificación con márgenes máximos, separación no lineal               | Bueno para datasets pequeños, puede ser lento en grandes   |\n",
    "| **K-Nearest Neighbors (KNN)**                      | Clasificación/Regresión                         | Basado en vecinos más cercanos (proximidad)                            | Fácil de entender, costoso en predicción                   |\n",
    "| **Naive Bayes**                                    | Clasificación                                   | Clasificación de textos, spam, sentimiento, etc.                       | Rápido, asume independencia entre variables                |\n",
    "| **DummyClassifier / DummyRegressor**               | Baseline (referencia)                           | Comparar con modelos tontos (estrategias simples)                      | No aprende, útil como base de comparación                  |\n",
    "| **Linear Discriminant Analysis (LDA)**             | Clasificación                                   | Clasificación con reducción de dimensionalidad                         | Bueno con datos linealmente separables                     |\n",
    "| **Quadratic Discriminant Analysis (QDA)**          | Clasificación                                   | Igual que LDA, pero para datos con covarianzas diferentes entre clases | Más flexible, pero más complejo                            |\n",
    "| **Stochastic Gradient Descent (SGD)**              | Clasificación/Regresión                         | Casos con grandes volúmenes de datos                                   | Ligero, útil en streaming y textos                         |\n",
    "| **Multilayer Perceptron (MLP - Redes neuronales)** | Clasificación/Regresión                         | Problemas no lineales complejos                                        | Aprende patrones no lineales, requiere más datos           |\n",
    "| **K-Means**                                        | Clustering (no supervisado)                     | Agrupar datos similares sin etiquetas                                  | Fácil de usar, no requiere etiquetas                       |\n",
    "| **DBSCAN**                                         | Clustering (no supervisado)                     | Agrupar con formas arbitrarias y detectar outliers                     | Útil para detectar ruido, no requiere especificar K        |\n",
    "| **Hierarchical Clustering**                        | Clustering (no supervisado)                     | Agrupación por jerarquía (árbol de similitud)                          | Visualización con dendrogramas                             |\n",
    "| **PCA (Análisis de Componentes Principales)**      | Reducción de dimensionalidad                    | Visualización, eliminar ruido, acelerar algoritmos                     | Proyecta los datos a un nuevo espacio                      |\n",
    "| **t-SNE / UMAP**                                   | Reducción de dimensionalidad                    | Visualización de datos en 2D o 3D                                      | Útiles en visualización de clusters                        |\n",
    "| **ARIMA / SARIMA**                                 | Series temporales                               | Predicción de datos secuenciales con tendencias y estacionalidad       | Requiere datos ordenados temporalmente                     |\n",
    "| **Facebook Prophet**                               | Series temporales                               | Predicción de series de tiempo con eventos y estacionalidad            | Fácil de usar, útil para negocios                          |\n",
    "| **LSTM (Redes recurrentes)**                       | Series temporales / Secuencias                  | Modelado de secuencias complejas (texto, tiempo, audio)                | Potente, usado en deep learning                            |\n",
    "| **Autoencoder**                                    | Reducción de dimensión / Detección de anomalías | Aprender representación comprimida de datos                            | Parte de redes neuronales                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d25a2",
   "metadata": {},
   "source": [
    "## [___] 5. Predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4a761",
   "metadata": {},
   "source": [
    "## [✅] 5. Predecir\n",
    "- [__] Entrené el modelo con `.fit(X_train, y_train)`\n",
    "\n",
    "- [__] Usé `.predict(X_test)` para obtener las predicciones\n",
    "\n",
    "- [__] Guardé las predicciones en `y_pred`\n",
    "\n",
    "- [__] Verifiqué que `y_pred` tenga la misma longitud que `y_test`\n",
    "\n",
    "- [__] (Opcional) Usé `.predict_proba()` si quería probabilidades\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d86576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar predicciones con valores reales\n",
    "for real, pred in zip(y_test[:5], y_pred[:5]):\n",
    "    print(f\"Real: {real} - Predicho: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d051999",
   "metadata": {},
   "source": [
    "## [___] 6. Comparar varios modelos\n",
    "\n",
    "- [__] Elegí al menos dos modelos diferentes\n",
    "\n",
    "- [__] Entrené cada modelo con `.fit()`\n",
    "\n",
    "- [__] Predije los resultados con `.predict()`\n",
    "\n",
    "- [__] Evalué cada modelo con métricas relevantes\n",
    "\n",
    "- [__] Guardé los resultados en una estructura organizada\n",
    "\n",
    "- [__] Comparé las métricas para decidir cuál modelo usar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a3568",
   "metadata": {},
   "source": [
    "💡 Consejos:\n",
    "Empieza con modelos simples (baseline).\n",
    "\n",
    "Prueba validación cruzada (cross_val_score).\n",
    "\n",
    "Usa Pipeline para integrar transformaciones y modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "program_exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
