# exploracion 
## Estructura de carpetas( recomendado )
ğŸ“ Proyecto_Analisis_Datos/
â”‚
â”œâ”€â”€ ğŸ“‚ 0_Documentacion/
â”‚   â”œâ”€â”€ README.md                 # DescripciÃ³n general del proyecto
â”‚   â”œâ”€â”€ planteamiento_problema.md # Objetivos, hipÃ³tesis, preguntas de anÃ¡lisis
â”‚   â”œâ”€â”€ diccionario_datos.md      # ExplicaciÃ³n de cada variable
â”‚   â”œâ”€â”€ referencias.md            # BibliografÃ­a, enlaces, papers
â”‚   â””â”€â”€ requisitos.md             # Dependencias, librerÃ­as, versiones
â”‚
â”œâ”€â”€ ğŸ“‚ 1_Datos/
â”‚   â”œâ”€â”€ ğŸ“‚ brutos/                 # Datos originales (sin modificar)
â”‚   â”œâ”€â”€ ğŸ“‚ procesados/             # Datos limpios y transformados
â”‚   â”œâ”€â”€ ğŸ“‚ externos/               # Datos de APIs, scraping, encuestas, etc.
â”‚   â””â”€â”€ ğŸ“‚ diccionarios/           # Diccionarios de variables y catÃ¡logos
â”‚
â”œâ”€â”€ ğŸ“‚ 2_Notebooks/                # ExploraciÃ³n, limpieza y pruebas rÃ¡pidas
â”‚   â”œâ”€â”€ 01_exploracion.ipynb
â”‚   â”œâ”€â”€ 02_limpieza.ipynb
â”‚   â””â”€â”€ 03_modelado.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ 3_Scripts/                  # CÃ³digo reutilizable en Python/R/etc.
â”‚   â”œâ”€â”€ limpieza.py
â”‚   â”œâ”€â”€ visualizacion.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â””â”€â”€ modelos.py
â”‚
â”œâ”€â”€ ğŸ“‚ 4_Resultados/
â”‚   â”œâ”€â”€ ğŸ“‚ graficos/               # Visualizaciones (png, jpg, svg)
â”‚   â”œâ”€â”€ ğŸ“‚ tablas/                 # Tablas exportadas (csv, xlsx)
â”‚   â””â”€â”€ ğŸ“‚ reportes/               # Reportes parciales en PDF/MD
â”‚
â”œâ”€â”€ ğŸ“‚ 5_Modelos/ (opcional IA/ML) 
â”‚   â”œâ”€â”€ ğŸ“‚ entrenados/             # Modelos entrenados (.pkl, .h5, .onnx)
â”‚   â”œâ”€â”€ ğŸ“‚ evaluaciones/           # Resultados de mÃ©tricas, validaciones
â”‚   â””â”€â”€ ğŸ“‚ tuning/                 # ConfiguraciÃ³n de hiperparÃ¡metros
â”‚
â”œâ”€â”€ ğŸ“‚ 6_Implementacion/ (opcional IA/ProducciÃ³n)
â”‚   â”œâ”€â”€ api_servicios/             # Scripts de despliegue en API (FastAPI, Flask)
â”‚   â”œâ”€â”€ pipelines/                 # ETL, automatizaciones
â”‚   â””â”€â”€ dashboards/                # Paneles web interactivos (Streamlit, Dash)
â”‚
â”œâ”€â”€ ğŸ“‚ 7_PowerBI_Excel/ (opcional para proyectos BI)
â”‚   â”œâ”€â”€ reportes_powerbi.pbix
â”‚   â””â”€â”€ reportes_excel.xlsx
â”‚
â”œâ”€â”€ ğŸ“‚ 8_Tests/ (opcional avanzado)
â”‚   â”œâ”€â”€ unit_tests.py              # Pruebas unitarias
â”‚   â””â”€â”€ integracion_tests.py       # Pruebas de integraciÃ³n
â”‚
â””â”€â”€ ğŸ“‚ 9_Entrega_Final/
    â”œâ”€â”€ informe_final.md           # Documento final del anÃ¡lisis
    â”œâ”€â”€ presentacion.pptx          # PresentaciÃ³n ejecutiva
    â””â”€â”€ dashboard_link.txt         # Enlace a PowerBI/Streamlit/otro


## 1. Definir la fuente y permisos
- [ ] Identificar tipo de fuente: archivo (CSV/Excel/JSON/Parquet), API, BD, web scraping.  
- [ ] Verificar autorizaciones y credenciales (manejo seguro: `.env` o variables de entorno).  
- [ ] Establecer frecuencia de actualizaciÃ³n y corte temporal.  

## 2. Trazabilidad mÃ­nima
- [ ] Guardar copia en `data/raw/` (datos tal cual llegan).  
- [ ] Calcular hash (sha256) del archivo fuente.  
- [ ] Registrar fecha/hora de ingesta.  
- [ ] Documentar responsable y parÃ¡metros de carga.  

## 3. EstÃ¡ndar de almacenamiento
- [ ] ConvenciÃ³n de nombres: `dataset_YYYYMMDD_origen.ext`.  
- [ ] Subcarpetas: `raw/`, `staging/`, `logs/`.  

## 4. DetecciÃ³n inicial de formato
- [ ] Detectar encoding (UTF-8, latin-1).  
- [ ] Identificar delimitador (`,` `;` `\t`).  
- [ ] Confirmar formato de fechas, decimales y separadores de miles.  

## 5. ExploraciÃ³n preliminar (sin limpiar)
- [ ] NÃºmero de filas y columnas cargadas.  
- [ ] Nombres de columnas â†’ estandarizar a `snake_case`.  
- [ ] Tipos inferidos (numÃ©rico, texto, fecha, categÃ³rico).  
- [ ] Conteo de nulos por columna.  
- [ ] Conteo de duplicados (fila completa y por PK).  
- [ ] Columnas constantes o con un solo valor.  

## 6. Diccionario preliminar de datos
- [ ] Tipo de dato por columna.  
- [ ] % de valores nulos.  
- [ ] NÃºmero de valores Ãºnicos.  
- [ ] Valores mÃ­nimos y mÃ¡ximos (numÃ©ricos/fechas).  
- [ ] Ejemplos de valores.  

## 7. Privacidad y compliance
- [ ] Identificar posibles datos sensibles (PII: cÃ©dula, correo, telÃ©fono).  
- [ ] Enmascarar o excluir si no son necesarios para el anÃ¡lisis.  

## 8. Salidas de la fase
- [ ] Dataset en formato **Parquet** (colunar, comprimido).  
- [ ] Diccionario preliminar en CSV/Markdown.  
- [ ] Log JSON con metadatos de carga (origen, hash, encoding, filas, columnas, incidencias).  